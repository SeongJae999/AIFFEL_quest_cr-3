{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/incheonQ/AIFFEL_quest_cr/blob/main/Keras/subquestb17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxllJJ7autOJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7a50d2e-f405-417f-89a5-385a734e1046"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "\u001b[1m2110848/2110848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data[0]), len(train_data[1]), len(train_data[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSRMajVluuk0",
        "outputId": "0f681c89-8105-487d-ecb3-b5a7e455622f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(87, 56, 139)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        for j in sequence:\n",
        "            results[i, j] = 1.\n",
        "    return results\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "metadata": {
        "id": "S3KzpM_lzQwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQair8UBzpZC",
        "outputId": "b7500652-6430-487a-d60d-75fa7559a17c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8982, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 라벨 46개"
      ],
      "metadata": {
        "collapsed": true,
        "id": "0ttktyYpzqHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "\n",
        "# User-defined block (Model Subclassing)\n",
        "class CustomBlock(Model):\n",
        "    def __init__(self, units, activation='relu'):\n",
        "        super(CustomBlock, self).__init__()\n",
        "        self.dense1 = Dense(units, activation=activation)\n",
        "        self.dense2 = Dense(units // 2, activation=activation)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        return self.dense2(x)\n",
        "\n",
        "# User-defined model class\n",
        "class CustomModel(Model):\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.block1 = CustomBlock(64)\n",
        "        self.output_layer = Dense(46, activation='softmax')\n",
        "\n",
        "    # Deeper structure\n",
        "    def call(self, inputs):\n",
        "        x = self.block1(inputs)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "    # Custom training step without learning rate adjustment\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)  # Model prediction\n",
        "            loss = self.compiled_loss(y, y_pred)  # Calculate loss\n",
        "\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "# Create the model\n",
        "model = CustomModel()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Build and summarize the model\n",
        "model.build(input_shape=(None, 10000))\n",
        "model.summary()\n",
        "\n",
        "# Define the learning rate scheduler callback\n",
        "def lr_scheduler(epoch, lr):\n",
        "    if epoch != 0 and epoch % 5 == 0:\n",
        "        new_lr = lr * 0.9\n",
        "        print(f\"\\nEpoch {epoch}: Learning rate adjusted to {new_lr:.5f}.\")\n",
        "        return new_lr\n",
        "    return lr\n",
        "\n",
        "# When fitting the model, use the LearningRateScheduler\n",
        "# model.fit(train_dataset, epochs=..., callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_scheduler)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "ew89ynyk0AGi",
        "outputId": "6d20f4c6-2ecf-4d7e-bf8a-0cb8446daab4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:372: UserWarning: `build()` was called on layer 'custom_model', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"custom_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"custom_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ custom_block (\u001b[38;5;33mCustomBlock\u001b[0m)           │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ custom_block (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomBlock</span>)           │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer = model.fit(x=x_train, y=tf.keras.utils.to_categorical(train_labels), batch_size=512, epochs=20, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVDVodKz0Xzp",
        "outputId": "59dfab30-744b-4ec7-9efa-c023c9d9276e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py:607: UserWarning: `model.compiled_loss()` is deprecated. Instead, use `model.compute_loss(x, y, y_pred, sample_weight, training)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py:582: UserWarning: `model.compiled_metrics()` is deprecated. Instead, use e.g.:\n",
            "```\n",
            "for metric in self.metrics:\n",
            "    metric.update_state(y, y_pred)\n",
            "```\n",
            "\n",
            "  return self._compiled_metrics_update_state(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - accuracy: 0.3103 - loss: 0.0217 - val_accuracy: 0.5698 - val_loss: 2.6910\n",
            "Epoch 2/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.5790 - loss: 0.0217 - val_accuracy: 0.6127 - val_loss: 1.8016\n",
            "Epoch 3/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6456 - loss: 0.0217 - val_accuracy: 0.6878 - val_loss: 1.4555\n",
            "Epoch 4/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.7398 - loss: 0.0217 - val_accuracy: 0.7262 - val_loss: 1.2748\n",
            "Epoch 5/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.7870 - loss: 0.0217 - val_accuracy: 0.7457 - val_loss: 1.1695\n",
            "Epoch 6/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8297 - loss: 0.0217 - val_accuracy: 0.7641 - val_loss: 1.0957\n",
            "Epoch 7/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8631 - loss: 0.0217 - val_accuracy: 0.7780 - val_loss: 1.0391\n",
            "Epoch 8/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8842 - loss: 0.0217 - val_accuracy: 0.7841 - val_loss: 1.0067\n",
            "Epoch 9/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9150 - loss: 0.0217 - val_accuracy: 0.7947 - val_loss: 0.9783\n",
            "Epoch 10/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9279 - loss: 0.0217 - val_accuracy: 0.7974 - val_loss: 0.9636\n",
            "Epoch 11/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9401 - loss: 0.0217 - val_accuracy: 0.7947 - val_loss: 0.9647\n",
            "Epoch 12/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9458 - loss: 0.0217 - val_accuracy: 0.7997 - val_loss: 0.9584\n",
            "Epoch 13/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - accuracy: 0.9549 - loss: 0.0217 - val_accuracy: 0.7991 - val_loss: 0.9634\n",
            "Epoch 14/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9570 - loss: 0.0217 - val_accuracy: 0.7947 - val_loss: 0.9786\n",
            "Epoch 15/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9570 - loss: 0.0217 - val_accuracy: 0.7991 - val_loss: 0.9713\n",
            "Epoch 16/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9646 - loss: 0.0217 - val_accuracy: 0.7974 - val_loss: 0.9895\n",
            "Epoch 17/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9604 - loss: 0.0217 - val_accuracy: 0.7963 - val_loss: 1.0005\n",
            "Epoch 18/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9650 - loss: 0.0217 - val_accuracy: 0.7924 - val_loss: 1.0225\n",
            "Epoch 19/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9668 - loss: 0.0217 - val_accuracy: 0.7969 - val_loss: 1.0191\n",
            "Epoch 20/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9686 - loss: 0.0217 - val_accuracy: 0.7986 - val_loss: 1.0296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_training_history(history):\n",
        "    # 학습 및 검증 손실 시각화\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # 학습 및 검증 정확도 시각화\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 모델 학습 후 결과 시각화\n",
        "plot_training_history(layer)"
      ],
      "metadata": {
        "id": "b7svCVl0Co_g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "outputId": "35673f05-3ce8-468d-c6c2-a78d0f90825f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 레이어 변경"
      ],
      "metadata": {
        "id": "dGy37D4XB_Zv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 레이어를 넓게 변경해보기"
      ],
      "metadata": {
        "id": "mRfGF8tt3UlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 레이어를 넓게 변경\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "\n",
        "# 사용자 정의 블록 (모델 서브클래싱)\n",
        "class CustomBlock(Model):\n",
        "    def __init__(self, units, activation='relu'):\n",
        "        super(CustomBlock, self).__init__()\n",
        "        self.dense1 = Dense(units * 2, activation=activation)  # 유닛 수를 2배로 늘림\n",
        "        self.dense2 = Dense(units, activation=activation)  # 유닛 수를 그대로 유지\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        return self.dense2(x)\n",
        "\n",
        "# 사용자 정의 모델 클래스\n",
        "class CustomModel(Model):\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.block1 = CustomBlock(128)  # 유닛 수를 128로 증가\n",
        "        self.output_layer = Dense(46, activation='softmax')\n",
        "\n",
        "    # 깊은 구조\n",
        "    def call(self, inputs):\n",
        "        x = self.block1(inputs)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "    # 학습률 조정 없이 사용자 정의 학습 단계\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)  # 모델 예측\n",
        "            loss = self.compiled_loss(y, y_pred)  # 손실 계산\n",
        "\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "# 모델 생성\n",
        "model = CustomModel()\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 빌드 및 요약\n",
        "model.build(input_shape=(None, 10000))\n",
        "model.summary()\n",
        "\n",
        "# 학습률 스케줄러 콜백 정의\n",
        "def lr_scheduler(epoch, lr):\n",
        "    if epoch != 0 and epoch % 5 == 0:\n",
        "        new_lr = lr * 0.9\n",
        "        print(f\"\\nEpoch {epoch}: 학습률이 {new_lr:.5f}로 조정되었습니다.\")\n",
        "        return new_lr\n",
        "    return lr\n",
        "\n",
        "# 모델 학습 시 LearningRateScheduler 사용\n",
        "# model.fit(train_dataset, epochs=..., callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_scheduler)])\n"
      ],
      "metadata": {
        "id": "ssk39dIf0gPp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "c301956a-a8ca-4bce-f70b-bdbefd982b3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:372: UserWarning: `build()` was called on layer 'custom_model_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"custom_model_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"custom_model_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ custom_block_1 (\u001b[38;5;33mCustomBlock\u001b[0m)         │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ custom_block_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomBlock</span>)         │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wide_layer = model.fit(x=x_train, y=tf.keras.utils.to_categorical(train_labels), batch_size=512, epochs=20, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8GyTvig3Ntz",
        "outputId": "c3695944-1a86-4bcd-d719-ef5a5b9775be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 196ms/step - accuracy: 0.3925 - loss: 0.0217 - val_accuracy: 0.6477 - val_loss: 1.6824\n",
            "Epoch 2/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - accuracy: 0.6916 - loss: 0.0217 - val_accuracy: 0.7362 - val_loss: 1.2623\n",
            "Epoch 3/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - accuracy: 0.7918 - loss: 0.0217 - val_accuracy: 0.7679 - val_loss: 1.0675\n",
            "Epoch 4/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 142ms/step - accuracy: 0.8509 - loss: 0.0217 - val_accuracy: 0.7941 - val_loss: 0.9653\n",
            "Epoch 5/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.9089 - loss: 0.0217 - val_accuracy: 0.7991 - val_loss: 0.9587\n",
            "Epoch 6/20\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 700ms/step - accuracy: 0.9297 - loss: 0.0217"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습 후 결과 시각화\n",
        "plot_training_history(wide_layer)"
      ],
      "metadata": {
        "id": "QxJZIv4JCZLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 레이어를 깊게 변경해보기"
      ],
      "metadata": {
        "id": "RTSxNYNd3nGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "\n",
        "# 사용자 정의 블록 (모델 서브클래싱)\n",
        "class CustomBlock(Model):\n",
        "    def __init__(self, units, activation='relu'):\n",
        "        super(CustomBlock, self).__init__()\n",
        "        self.dense1 = Dense(units, activation=activation)  # 유닛 수를 그대로 유지\n",
        "        self.dense2 = Dense(units, activation=activation)  # 유닛 수를 그대로 유지\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        return self.dense2(x)\n",
        "\n",
        "# 사용자 정의 모델 클래스\n",
        "class CustomModel(Model):\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.block1 = CustomBlock(64)  # 유닛 수를 64로 설정\n",
        "        self.block2 = CustomBlock(64)  # 두 번째 블록 추가\n",
        "        self.block3 = CustomBlock(64)  # 세 번째 블록 추가\n",
        "        self.output_layer = Dense(46, activation='softmax')\n",
        "\n",
        "    # 깊은 구조\n",
        "    def call(self, inputs):\n",
        "        x = self.block1(inputs)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "    # 학습률 조정 없이 사용자 정의 학습 단계\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)  # 모델 예측\n",
        "            loss = self.compiled_loss(y, y_pred)  # 손실 계산\n",
        "\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "# 모델 생성\n",
        "model = CustomModel()\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 빌드 및 요약\n",
        "model.build(input_shape=(None, 10000))\n",
        "model.summary()\n",
        "\n",
        "# 학습률 스케줄러 콜백 정의\n",
        "def lr_scheduler(epoch, lr):\n",
        "    if epoch != 0 and epoch % 5 == 0:\n",
        "        new_lr = lr * 0.9\n",
        "        print(f\"\\nEpoch {epoch}: 학습률이 {new_lr:.5f}로 조정되었습니다.\")\n",
        "        return new_lr\n",
        "    return lr\n",
        "\n",
        "# 모델 학습 시 LearningRateScheduler 사용\n",
        "# model.fit(train_dataset, epochs=..., callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_scheduler)])"
      ],
      "metadata": {
        "id": "7JSIlB-93YHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deep_layer = model.fit(x=x_train, y=tf.keras.utils.to_categorical(train_labels), batch_size=512, epochs=20, validation_split=0.2)"
      ],
      "metadata": {
        "id": "AmZAUjT83qu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습 후 결과 시각화\n",
        "plot_training_history(deep_layer)"
      ],
      "metadata": {
        "id": "DI7eJFNsCg4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3가지 그래프를 비교하기 위해 한번에 학습 진행"
      ],
      "metadata": {
        "id": "cg4O5XjHC0vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 사용자 정의 블록 (모델 서브클래싱)\n",
        "class CustomBlock(Model):\n",
        "    def __init__(self, units, activation='relu'):\n",
        "        super(CustomBlock, self).__init__()\n",
        "        self.dense1 = Dense(units, activation=activation)  # 유닛 수를 그대로 유지\n",
        "        self.dense2 = Dense(units, activation=activation)  # 유닛 수를 그대로 유지\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        return self.dense2(x)\n",
        "\n",
        "# 사용자 정의 모델 클래스\n",
        "class CustomModel(Model):\n",
        "    def __init__(self, depth=1, units=64):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.blocks = [CustomBlock(units) for _ in range(depth)]  # 깊이에 따라 블록 생성\n",
        "        self.output_layer = Dense(46, activation='softmax')\n",
        "\n",
        "    # 깊은 구조\n",
        "    def call(self, inputs):\n",
        "        x = inputs\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "    # 학습률 조정 없이 사용자 정의 학습 단계\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)  # 모델 예측\n",
        "            loss = self.compiled_loss(y, y_pred)  # 손실 계산\n",
        "\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "# 모델 생성\n",
        "layer = CustomModel(depth=1, units=64)  # 기본 레이어\n",
        "wide_layer = CustomModel(depth=1, units=128)  # 넓은 레이어\n",
        "deep_layer = CustomModel(depth=3, units=64)  # 깊은 레이어\n",
        "\n",
        "# 모델 컴파일\n",
        "for model in [layer, wide_layer, deep_layer]:\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.build(input_shape=(None, 10000))\n",
        "    model.summary()\n",
        "\n",
        "# 학습률 스케줄러 콜백 정의\n",
        "def lr_scheduler(epoch, lr):\n",
        "    if epoch != 0 and epoch % 5 == 0:\n",
        "        new_lr = lr * 0.9\n",
        "        print(f\"\\nEpoch {epoch}: 학습률이 {new_lr:.5f}로 조정되었습니다.\")\n",
        "        return new_lr\n",
        "    return lr\n",
        "\n",
        "# 모델 학습\n",
        "histories = {}\n",
        "for model_name, model in zip(['layer', 'wide_layer', 'deep_layer'], [layer, wide_layer, deep_layer]):\n",
        "    histories[model_name] = model.fit(x=x_train, y=tf.keras.utils.to_categorical(train_labels),\n",
        "                                      batch_size=512, epochs=20, validation_split=0.2,\n",
        "                                      callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_scheduler)])\n",
        "\n",
        "# 학습 결과 시각화\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# 손실 그래프 그리기\n",
        "plt.subplot(1, 2, 1)\n",
        "for model_name, history in histories.items():\n",
        "    plt.plot(history.history['loss'], label=f'{model_name} 훈련 손실')\n",
        "    plt.plot(history.history['val_loss'], linestyle='--', label=f'{model_name} 검증 손실')\n",
        "plt.xlabel('에포크')\n",
        "plt.ylabel('손실')\n",
        "plt.title('훈련 및 검증 손실 비교')\n",
        "plt.legend()\n",
        "\n",
        "# 정확도 그래프 그리기\n",
        "plt.subplot(1, 2, 2)\n",
        "for model_name, history in histories.items():\n",
        "    plt.plot(history.history['accuracy'], label=f'{model_name} 훈련 정확도')\n",
        "    plt.plot(history.history['val_accuracy'], linestyle='--', label=f'{model_name} 검증 정확도')\n",
        "plt.xlabel('에포크')\n",
        "plt.ylabel('정확도')\n",
        "plt.title('훈련 및 검증 정확도 비교')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1SG7gxlx3w6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 결과 시각화\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# 손실 그래프 그리기\n",
        "plt.subplot(1, 2, 1)\n",
        "for model_name, history in histories.items():\n",
        "    plt.plot(history.history['loss'], label=f'{model_name} Training Loss')\n",
        "    plt.plot(history.history['val_loss'], linestyle='--', label=f'{model_name} Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss Comparison')\n",
        "plt.legend()\n",
        "\n",
        "# 정확도 그래프 그리기\n",
        "plt.subplot(1, 2, 2)\n",
        "for model_name, history in histories.items():\n",
        "    plt.plot(history.history['accuracy'], label=f'{model_name} Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], linestyle='--', label=f'{model_name} Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy Comparison')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0p-cIf8k39xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### layer 변경에 따른 차이\n",
        "- 해당 데이터에서는 기존 layer보다 deep layer에서 학습이 더 늦었음\n",
        "- deep에서 눈에 띄게 validation loss 값이 눈에 띄게 낮음."
      ],
      "metadata": {
        "id": "9f3tT5Y-D8B5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Learning rate 변경"
      ],
      "metadata": {
        "id": "7-WfbSvaDBTJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0.1"
      ],
      "metadata": {
        "id": "TdKrJHBB3ZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "\n",
        "# User-defined block (Model Subclassing)\n",
        "class CustomBlock(Model):\n",
        "    def __init__(self, units, activation='relu'):\n",
        "        super(CustomBlock, self).__init__()\n",
        "        self.dense1 = Dense(units, activation=activation)\n",
        "        self.dense2 = Dense(units // 2, activation=activation)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        return self.dense2(x)\n",
        "\n",
        "# User-defined model class\n",
        "class CustomModel(Model):\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.block1 = CustomBlock(64)\n",
        "        self.output_layer = Dense(46, activation='softmax')\n",
        "\n",
        "    # Deeper structure\n",
        "    def call(self, inputs):\n",
        "        x = self.block1(inputs)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "    # Custom training step without learning rate adjustment\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)  # Model prediction\n",
        "            loss = self.compiled_loss(y, y_pred)  # Calculate loss\n",
        "\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "# Create the model\n",
        "model = CustomModel()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Build and summarize the model\n",
        "model.build(input_shape=(None, 10000))\n",
        "model.summary()\n",
        "\n",
        "# Define the learning rate scheduler callback\n",
        "def lr_scheduler(epoch, lr):\n",
        "    if epoch != 0 and epoch % 5 == 0:\n",
        "        new_lr = lr * 0.9\n",
        "        print(f\"\\nEpoch {epoch}: Learning rate adjusted to {new_lr:.5f}.\")\n",
        "        return new_lr\n",
        "    return lr\n",
        "\n",
        "# When fitting the model, use the LearningRateScheduler\n",
        "# model.fit(train_dataset, epochs=..., callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_scheduler)])"
      ],
      "metadata": {
        "id": "RYKJ29EnDuHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x=x_train, y=tf.keras.utils.to_categorical(train_labels), batch_size=512, epochs=20, validation_split=0.2)"
      ],
      "metadata": {
        "id": "rnY7IP0cDuHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "history_dict.keys()\n",
        "history_dict = history.history\n",
        "loss_values = history_dict[\"loss\"]\n",
        "val_loss_values = history_dict[\"val_loss\"]\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HFMqnLRoDuHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0.01"
      ],
      "metadata": {
        "id": "VS_xid433UAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "\n",
        "# User-defined block (Model Subclassing)\n",
        "class CustomBlock(Model):\n",
        "    def __init__(self, units, activation='relu'):\n",
        "        super(CustomBlock, self).__init__()\n",
        "        self.dense1 = Dense(units, activation=activation)\n",
        "        self.dense2 = Dense(units // 2, activation=activation)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        return self.dense2(x)\n",
        "\n",
        "# User-defined model class\n",
        "class CustomModel(Model):\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.block1 = CustomBlock(64)\n",
        "        self.output_layer = Dense(46, activation='softmax')\n",
        "\n",
        "    # Deeper structure\n",
        "    def call(self, inputs):\n",
        "        x = self.block1(inputs)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "    # Custom training step without learning rate adjustment\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)  # Model prediction\n",
        "            loss = self.compiled_loss(y, y_pred)  # Calculate loss\n",
        "\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "# Create the model\n",
        "model = CustomModel()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Build and summarize the model\n",
        "model.build(input_shape=(None, 10000))\n",
        "model.summary()\n",
        "\n",
        "# Define the learning rate scheduler callback\n",
        "def lr_scheduler(epoch, lr):\n",
        "    if epoch != 0 and epoch % 5 == 0:\n",
        "        new_lr = lr * 0.9\n",
        "        print(f\"\\nEpoch {epoch}: Learning rate adjusted to {new_lr:.5f}.\")\n",
        "        return new_lr\n",
        "    return lr\n",
        "\n",
        "# When fitting the model, use the LearningRateScheduler\n",
        "# model.fit(train_dataset, epochs=..., callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_scheduler)])"
      ],
      "metadata": {
        "id": "x3uEau3b3kux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x=x_train, y=tf.keras.utils.to_categorical(train_labels), batch_size=512, epochs=20, validation_split=0.2)"
      ],
      "metadata": {
        "id": "fAmnfEdD3kuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "history_dict.keys()\n",
        "history_dict = history.history\n",
        "loss_values = history_dict[\"loss\"]\n",
        "val_loss_values = history_dict[\"val_loss\"]\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aCz_GQqh3kuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0.005"
      ],
      "metadata": {
        "id": "p2DSntIx3Vij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "\n",
        "# User-defined block (Model Subclassing)\n",
        "class CustomBlock(Model):\n",
        "    def __init__(self, units, activation='relu'):\n",
        "        super(CustomBlock, self).__init__()\n",
        "        self.dense1 = Dense(units, activation=activation)\n",
        "        self.dense2 = Dense(units // 2, activation=activation)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        return self.dense2(x)\n",
        "\n",
        "# User-defined model class\n",
        "class CustomModel(Model):\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.block1 = CustomBlock(64)\n",
        "        self.output_layer = Dense(46, activation='softmax')\n",
        "\n",
        "    # Deeper structure\n",
        "    def call(self, inputs):\n",
        "        x = self.block1(inputs)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "    # Custom training step without learning rate adjustment\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)  # Model prediction\n",
        "            loss = self.compiled_loss(y, y_pred)  # Calculate loss\n",
        "\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "# Create the model\n",
        "model = CustomModel()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),\n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Build and summarize the model\n",
        "model.build(input_shape=(None, 10000))\n",
        "model.summary()\n",
        "\n",
        "# Define the learning rate scheduler callback\n",
        "def lr_scheduler(epoch, lr):\n",
        "    if epoch != 0 and epoch % 5 == 0:\n",
        "        new_lr = lr * 0.9\n",
        "        print(f\"\\nEpoch {epoch}: Learning rate adjusted to {new_lr:.5f}.\")\n",
        "        return new_lr\n",
        "    return lr\n",
        "\n",
        "# When fitting the model, use the LearningRateScheduler\n",
        "# model.fit(train_dataset, epochs=..., callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_scheduler)])"
      ],
      "metadata": {
        "id": "JmK0VqEi3lSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x=x_train, y=tf.keras.utils.to_categorical(train_labels), batch_size=512, epochs=20, validation_split=0.2)"
      ],
      "metadata": {
        "id": "31Jqeb303lSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "history_dict.keys()\n",
        "history_dict = history.history\n",
        "loss_values = history_dict[\"loss\"]\n",
        "val_loss_values = history_dict[\"val_loss\"]\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-XQDgRzb3lSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0.001"
      ],
      "metadata": {
        "id": "irQx0x4Z3Wxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "\n",
        "# User-defined block (Model Subclassing)\n",
        "class CustomBlock(Model):\n",
        "    def __init__(self, units, activation='relu'):\n",
        "        super(CustomBlock, self).__init__()\n",
        "        self.dense1 = Dense(units, activation=activation)\n",
        "        self.dense2 = Dense(units // 2, activation=activation)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        return self.dense2(x)\n",
        "\n",
        "# User-defined model class\n",
        "class CustomModel(Model):\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.block1 = CustomBlock(64)\n",
        "        self.output_layer = Dense(46, activation='softmax')\n",
        "\n",
        "    # Deeper structure\n",
        "    def call(self, inputs):\n",
        "        x = self.block1(inputs)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "    # Custom training step without learning rate adjustment\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)  # Model prediction\n",
        "            loss = self.compiled_loss(y, y_pred)  # Calculate loss\n",
        "\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "# Create the model\n",
        "model = CustomModel()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Build and summarize the model\n",
        "model.build(input_shape=(None, 10000))\n",
        "model.summary()\n",
        "\n",
        "# Define the learning rate scheduler callback\n",
        "def lr_scheduler(epoch, lr):\n",
        "    if epoch != 0 and epoch % 5 == 0:\n",
        "        new_lr = lr * 0.9\n",
        "        print(f\"\\nEpoch {epoch}: Learning rate adjusted to {new_lr:.5f}.\")\n",
        "        return new_lr\n",
        "    return lr\n",
        "\n",
        "# When fitting the model, use the LearningRateScheduler\n",
        "# model.fit(train_dataset, epochs=..., callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_scheduler)])"
      ],
      "metadata": {
        "id": "gNenHr4Q3lmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x=x_train, y=tf.keras.utils.to_categorical(train_labels), batch_size=512, epochs=20, validation_split=0.2)"
      ],
      "metadata": {
        "id": "YPG2PciF3lmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "history_dict.keys()\n",
        "history_dict = history.history\n",
        "loss_values = history_dict[\"loss\"]\n",
        "val_loss_values = history_dict[\"val_loss\"]\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xGGGu0i13lmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0.0005"
      ],
      "metadata": {
        "id": "FnOKlr6Z3w1R"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8oPNysm53y3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "\n",
        "# User-defined block (Model Subclassing)\n",
        "class CustomBlock(Model):\n",
        "    def __init__(self, units, activation='relu'):\n",
        "        super(CustomBlock, self).__init__()\n",
        "        self.dense1 = Dense(units, activation=activation)\n",
        "        self.dense2 = Dense(units // 2, activation=activation)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        return self.dense2(x)\n",
        "\n",
        "# User-defined model class\n",
        "class CustomModel(Model):\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.block1 = CustomBlock(64)\n",
        "        self.output_layer = Dense(46, activation='softmax')\n",
        "\n",
        "    # Deeper structure\n",
        "    def call(self, inputs):\n",
        "        x = self.block1(inputs)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "    # Custom training step without learning rate adjustment\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)  # Model prediction\n",
        "            loss = self.compiled_loss(y, y_pred)  # Calculate loss\n",
        "\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "# Create the model\n",
        "model = CustomModel()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Build and summarize the model\n",
        "model.build(input_shape=(None, 10000))\n",
        "model.summary()\n",
        "\n",
        "# Define the learning rate scheduler callback\n",
        "def lr_scheduler(epoch, lr):\n",
        "    if epoch != 0 and epoch % 5 == 0:\n",
        "        new_lr = lr * 0.9\n",
        "        print(f\"\\nEpoch {epoch}: Learning rate adjusted to {new_lr:.5f}.\")\n",
        "        return new_lr\n",
        "    return lr\n",
        "\n",
        "# When fitting the model, use the LearningRateScheduler\n",
        "# model.fit(train_dataset, epochs=..., callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_scheduler)])"
      ],
      "metadata": {
        "id": "sDtEmzdl30nJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x=x_train, y=tf.keras.utils.to_categorical(train_labels), batch_size=512, epochs=20, validation_split=0.2)"
      ],
      "metadata": {
        "id": "sXmIP7cM30nK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "history_dict.keys()\n",
        "history_dict = history.history\n",
        "loss_values = history_dict[\"loss\"]\n",
        "val_loss_values = history_dict[\"val_loss\"]\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E7zm8ysz30nK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### learning rate에 따른 차이\n",
        "- learning rate가 높은 경우, 빠르게 하한값에 접근하지만 극점에 수렴하지 못하고 진동하거나 극점을 지나친다.\n",
        "- learning rate가 낮은 경우, 극점에 수렴하기까지 시간이 오래 걸리지만(불필요한 학습) learning rate가 높을 때보다 더 낮은 loss 값을 보여준다. 때론, 지역최저점에 빠져 나오지 못하는 경우도 있음에 유의."
      ],
      "metadata": {
        "id": "DeA0etSmEPCH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. activation function 변경해보기\n",
        "- relu, tanh, sigmoid"
      ],
      "metadata": {
        "id": "N9eGMkEiESPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ReLU\n",
        "history_dict_sigmoid = history.history"
      ],
      "metadata": {
        "id": "yxr8d5CW-x_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# relu\n",
        "\n",
        "history_dict = history.history\n",
        "loss_values = history_dict[\"loss\"]\n",
        "val_loss_values = history_dict[\"val_loss\"]\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CQiW8SWFEl7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tanh\n",
        "\n",
        "history_dict = history.history\n",
        "loss_values = history_dict[\"loss\"]\n",
        "val_loss_values = history_dict[\"val_loss\"]\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fM9bV4bb3JVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sigmoid\n",
        "\n",
        "history_dict = history.history\n",
        "loss_values = history_dict[\"loss\"]\n",
        "val_loss_values = history_dict[\"val_loss\"]\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9Tc6qTK56e6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ReLU\n",
        "loss_values_relu = history_dict_relu[\"loss\"]\n",
        "val_loss_values_relu = history_dict_relu[\"val_loss\"]\n",
        "\n",
        "loss_values_tanh = history_dict_tanh[\"loss\"]\n",
        "val_loss_values_tanh = history_dict_tanh[\"val_loss\"]\n",
        "\n",
        "# Sigmoid\n",
        "loss_values_sigmoid = history_dict_sigmoid[\"loss\"]\n",
        "val_loss_values_sigmoid = history_dict_sigmoid[\"val_loss\"]\n",
        "\n",
        "# Epochs range\n",
        "epochs = range(1, len(loss_values_relu) + 1)\n",
        "\n",
        "# Plot training loss\n",
        "plt.plot(epochs, loss_values_relu, \"r-\", label=\"ReLU Training loss\")\n",
        "plt.plot(epochs, loss_values_tanh, \"g-\", label=\"Tanh Training loss\")\n",
        "plt.plot(epochs, loss_values_sigmoid, \"b-\", label=\"Sigmoid Training loss\")\n",
        "\n",
        "# Plot validation loss\n",
        "plt.plot(epochs, val_loss_values_relu, \"r--\", label=\"ReLU Validation loss\")\n",
        "plt.plot(epochs, val_loss_values_tanh, \"g--\", label=\"Tanh Validation loss\")\n",
        "plt.plot(epochs, val_loss_values_sigmoid, \"b--\", label=\"Sigmoid Validation loss\")\n",
        "\n",
        "# Graph details\n",
        "plt.title(\"Training and Validation Loss Comparison\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kQEUlA5f63QQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### activation function 변경에 따른 차이\n",
        "- 단순히 loss율로 따졌을 때 Sigmoid < ReLU < Tanh 순으로 성능이 좋다고 볼 수 있다.\n",
        "- ReLU와 Tanh의 성능은 비슷해 보이는데 첫 에포크의 loss율 시작점을 보면 가중치 초기값이 Tanh를 썼을 때 더 좋았던 모양이다."
      ],
      "metadata": {
        "id": "jICJ71r0Etz1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 회고 작성\n",
        "- 김민규 :\n",
        "  - 아쉬운 점\n",
        "\n",
        "    callback함수로 이미 구현되어 있는 기능이었다.\n",
        "\n",
        "    좀 더 복잡한 데이터셋을 사용해봤으면 하이퍼 파라미터 변화에 따른 결과의 차이가 두드러졌을 것 같다.)\n",
        "  - 좋은 점\n",
        "    \n",
        "    직접 사용자 정의 모델을 작성해볼 수 있는 좋은 경험이었다.\n",
        "\n",
        "  - 앞으로\n",
        "  \n",
        "    다른 조에서 맡은 사용자 정의 평가 지표가 좀 더 중요한 내용인 것 같아 따로 시도해 볼 생각이다.\n",
        "\n",
        "- 김우찬 : 너무나 어렵습니다... 열심히 공부해보겠읍니다...\n",
        "\n",
        "- 김승기 : 7장에서 본 사용자 정의함수를 직접 테스트 해봤지만 아직 코드에 대한 이해가 부족한 것 같습니다. 책과 함께 보면서 계속 봐야 알 것 같습니다.\n",
        "\n",
        "## 우리의 학습템플릿\n",
        "- https://www.notion.so/modulabs/2b16dbae56d94193b676f562a41eeac3?p=42d95c72fac1493ba3fcdfc2f0a3db9b&pm=s"
      ],
      "metadata": {
        "id": "4L7-1Gg1EzLR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XUlQZ5trOwkP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}